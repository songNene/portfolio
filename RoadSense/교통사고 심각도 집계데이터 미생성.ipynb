{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae413612-48b5-4872-ab35-d5850001e1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accident-level Macro F1 (Logistic, no-EDA/no-aggregation): 0.510307427519219\n",
      "\n",
      "[Accident-level] classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Lethal       0.12      0.70      0.20       516\n",
      "   NonLethal       0.98      0.70      0.82      9049\n",
      "\n",
      "    accuracy                           0.70      9565\n",
      "   macro avg       0.55      0.70      0.51      9565\n",
      "weighted avg       0.93      0.70      0.79      9565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) 데이터 로드\n",
    "# =========================\n",
    "accidents = pd.read_csv(\"./data/accidents_clean.csv\")\n",
    "places    = pd.read_csv(\"./data/places_clean.csv\")\n",
    "users     = pd.read_csv(\"./data/users_clean.csv\")\n",
    "vehicles  = pd.read_csv(\"./data/vehicles_clean.csv\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) row-level 결합 (집계/EDA 없음)\n",
    "#    users 중심으로 vehicles를 (AccidentId, VehicleId)로 붙이면\n",
    "#    카디시안 폭발을 크게 줄이면서도 \"집계 없이\" raw 정보를 유지 가능\n",
    "# =========================\n",
    "row_df = (\n",
    "    users\n",
    "    .merge(vehicles, on=[\"AccidentId\", \"VehicleId\"], how=\"left\", suffixes=(\"\", \"_veh\"))\n",
    "    .merge(places,   on=\"AccidentId\", how=\"left\")\n",
    "    .merge(accidents[[\"AccidentId\", \"Gravity\"]], on=\"AccidentId\", how=\"left\")\n",
    ")\n",
    "\n",
    "# 라벨 없는 행 제거 (test 사고가 섞였거나 join 누락 시 대비)\n",
    "row_df = row_df.dropna(subset=[\"Gravity\"]).copy()\n",
    "\n",
    "y = row_df[\"Gravity\"]\n",
    "groups = row_df[\"AccidentId\"]\n",
    "\n",
    "X = row_df.drop(columns=[\"Gravity\"], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) Group split (AccidentId 기준, 누수 방지)\n",
    "# =========================\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "tr_idx, va_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train = X.iloc[tr_idx].copy()\n",
    "X_valid = X.iloc[va_idx].copy()\n",
    "y_train = y.iloc[tr_idx].copy()\n",
    "y_valid = y.iloc[va_idx].copy()\n",
    "\n",
    "gid_valid = groups.iloc[va_idx].values  # pooling용\n",
    "\n",
    "# 피처에서 그룹키 제거\n",
    "X_train = X_train.drop(columns=[\"AccidentId\"], errors=\"ignore\")\n",
    "X_valid = X_valid.drop(columns=[\"AccidentId\"], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) 전처리 + Logistic Regression\n",
    "#    - 수치: median impute + scaling\n",
    "#    - 범주: most_frequent impute + one-hot\n",
    "# =========================\n",
    "num_cols = X_train.select_dtypes(include=[\"int64\", \"float64\", \"Int64\"]).columns\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) 사고 단위 평가: row-level 확률 → AccidentId별 평균(pooling)\n",
    "# =========================\n",
    "proba = clf.predict_proba(X_valid)\n",
    "classes = clf.named_steps[\"model\"].classes_\n",
    "\n",
    "proba_by_acc = (\n",
    "    pd.DataFrame(proba, columns=classes)\n",
    "    .assign(AccidentId=gid_valid)\n",
    "    .groupby(\"AccidentId\")\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "y_by_acc = (\n",
    "    pd.DataFrame({\"AccidentId\": gid_valid, \"Gravity\": y_valid.values})\n",
    "    .drop_duplicates(\"AccidentId\")\n",
    "    .set_index(\"AccidentId\")\n",
    "    .loc[proba_by_acc.index, \"Gravity\"]\n",
    ")\n",
    "\n",
    "pred_by_acc = proba_by_acc.idxmax(axis=1)\n",
    "\n",
    "macro_f1 = f1_score(y_by_acc, pred_by_acc, average=\"macro\")\n",
    "\n",
    "print(\"Accident-level Macro F1 (Logistic, no-EDA/no-aggregation):\", macro_f1)\n",
    "print(\"\\n[Accident-level] classification report\")\n",
    "print(classification_report(y_by_acc, pred_by_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b38f5-d405-44d0-bfd8-7c4ee4d0fe3c",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afcabe16-d565-4eca-9ecb-56ea652386ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1690\n",
      "[LightGBM] [Info] Number of data points in the train set: 87004, number of used features: 64\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "LightGBM (row-level, no aggregation) Accident-level Macro F1: 0.588947698942953\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Lethal       0.19      0.34      0.24       516\n",
      "   NonLethal       0.96      0.92      0.94      9049\n",
      "\n",
      "    accuracy                           0.88      9565\n",
      "   macro avg       0.57      0.63      0.59      9565\n",
      "weighted avg       0.92      0.88      0.90      9565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0. 라이브러리\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1. 데이터 불러오기\n",
    "# =========================\n",
    "accidents = pd.read_csv(\"./data/accidents_clean.csv\")\n",
    "places    = pd.read_csv(\"./data/places_clean.csv\")\n",
    "users     = pd.read_csv(\"./data/users_clean.csv\")\n",
    "vehicles  = pd.read_csv(\"./data/vehicles_clean.csv\")\n",
    "\n",
    "# (핵심) 라벨 있는 사고만 남기기: Gravity NaN 제거\n",
    "acc_train = accidents.dropna(subset=[\"Gravity\"]).copy()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. row-level 데이터 결합 (집계/EDA 없음)\n",
    "# =========================\n",
    "row_df = (\n",
    "    users\n",
    "    .merge(vehicles, on=[\"AccidentId\", \"VehicleId\"], how=\"left\", suffixes=(\"\", \"_veh\"))\n",
    "    .merge(places, on=\"AccidentId\", how=\"left\")\n",
    "    .merge(acc_train[[\"AccidentId\", \"Gravity\"]], on=\"AccidentId\", how=\"inner\")  # 라벨 있는 사고만\n",
    ")\n",
    "\n",
    "# 타깃 / 그룹 / 입력 변수\n",
    "y = row_df[\"Gravity\"].copy()\n",
    "groups = row_df[\"AccidentId\"].copy()\n",
    "X = row_df.drop(columns=[\"Gravity\", \"AccidentId\"], errors=\"ignore\").copy()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. AccidentId 기준 Group split (누수 방지)\n",
    "# =========================\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, valid_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train = X.iloc[train_idx].copy()\n",
    "X_valid = X.iloc[valid_idx].copy()\n",
    "y_train = y.iloc[train_idx].copy()\n",
    "y_valid = y.iloc[valid_idx].copy()\n",
    "gid_valid = groups.iloc[valid_idx].values\n",
    "\n",
    "# (안전장치) 혹시라도 남아있으면 제거\n",
    "mask_tr = y_train.notna()\n",
    "X_train = X_train.loc[mask_tr].copy()\n",
    "y_train = y_train.loc[mask_tr].copy()\n",
    "\n",
    "mask_va = y_valid.notna()\n",
    "X_valid = X_valid.loc[mask_va].copy()\n",
    "y_valid = y_valid.loc[mask_va].copy()\n",
    "gid_valid = gid_valid[mask_va.values]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4. dtype 정리 + NaN 처리 (LightGBM용 최소 전처리)\n",
    "# =========================\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\", \"bool\", \"category\"]).columns.tolist()\n",
    "\n",
    "# category로 변환\n",
    "for c in cat_cols:\n",
    "    X_train[c] = X_train[c].astype(\"category\")\n",
    "    X_valid[c] = X_valid[c].astype(\"category\")\n",
    "\n",
    "# 범주형 NaN → \"Unknown\"\n",
    "for c in cat_cols:\n",
    "    if \"Unknown\" not in X_train[c].cat.categories:\n",
    "        X_train[c] = X_train[c].cat.add_categories([\"Unknown\"])\n",
    "    if \"Unknown\" not in X_valid[c].cat.categories:\n",
    "        X_valid[c] = X_valid[c].cat.add_categories([\"Unknown\"])\n",
    "    X_train[c] = X_train[c].fillna(\"Unknown\")\n",
    "    X_valid[c] = X_valid[c].fillna(\"Unknown\")\n",
    "\n",
    "# 수치형 NaN → -1\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "X_train[num_cols] = X_train[num_cols].fillna(-1)\n",
    "X_valid[num_cols] = X_valid[num_cols].fillna(-1)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5. LightGBM 모델 학습\n",
    "# =========================\n",
    "lgb_model = LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=y_train.nunique(),\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=63,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train, y_train, categorical_feature=cat_cols)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6. 사고 단위 평가 (row → AccidentId pooling)\n",
    "# =========================\n",
    "proba = lgb_model.predict_proba(X_valid)\n",
    "\n",
    "proba_by_acc = (\n",
    "    pd.DataFrame(proba)\n",
    "    .assign(AccidentId=gid_valid)\n",
    "    .groupby(\"AccidentId\")\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "y_by_acc = (\n",
    "    pd.DataFrame({\"AccidentId\": gid_valid, \"Gravity\": y_valid.values})\n",
    "    .drop_duplicates(\"AccidentId\")\n",
    "    .set_index(\"AccidentId\")\n",
    "    .loc[proba_by_acc.index, \"Gravity\"]\n",
    ")\n",
    "\n",
    "# 예측 클래스 라벨(문자)로 변환\n",
    "pred_by_acc = lgb_model.classes_[proba_by_acc.values.argmax(axis=1)]\n",
    "\n",
    "macro_f1 = f1_score(y_by_acc, pred_by_acc, average=\"macro\")\n",
    "\n",
    "print(\"LightGBM (row-level, no aggregation) Accident-level Macro F1:\", macro_f1)\n",
    "print(\"\\nClassification Report\")\n",
    "print(classification_report(y_by_acc, pred_by_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b2e304-a2d4-4f19-951a-7d2302657d13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dspp)",
   "language": "python",
   "name": "dspp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
